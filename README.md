<h1 align="center">AstroPunch â€“ Simulation & Klassifikation kosmischer Teilchen</h1>

---

## ğŸ“‘ Inhaltsverzeichnis
1. [DatensatzÃ¼bersicht](#-datensatzÃ¼bersicht)  
   - [ErklÃ¤rung](#erklÃ¤rung)  
   - [Struktur](#struktur)  
2. [Experimentelle Setups](#-experimentelle-setups)  
3. [Klassifikator-Architektur](#-klassifikator-architektur)  
4. [Ergebnisse](#-ergebnisse)  
   - [Baseline](#baseline)  
   - [Jitter-Augmentation](#jitter-augmentation)  
   - [Vortraining: Methode A vs. Methode B](#vortraining-vergleich-methode-a-vs-methode-b)  
   - [GAN-Augmentation](#gan-gestÃ¼tzte-augmentation)  
   - [Einfaches Vortraining](#einfaches-vortraining)  
   - [Kombinierte Augmentationsmethoden](#kombinierte-augmentationsmethoden)  

---

## ğŸ“‚ DatensatzÃ¼bersicht

In diesem Projekt werden fiktive DatensÃ¤tze nach folgender Struktur benannt:

{teilchenart}{umgebungsbedingung}{intensitÃ¤t}

markdown
Kopieren
Bearbeiten

Beispiel: `PRGA50`

### ErklÃ¤rung

- **teilchenart**:  
  Dieses Repository fokussiert sich auf simulierte kosmische Teilchenstrahlung (`PR` = Protonenstrahlung).

- **umgebungsbedingung**:  
  Zwei Szenarien werden verwendet:
  - `GA`: Galaktische Umgebung (fÃ¼r **Vortraining** der Modelle).
  - `SO`: SonnennÃ¤he (fÃ¼r **Feintuning** und **Evaluation**).

- **intensitÃ¤t**:  
  Verwendete Werte sind:  
  `{10, 20, 30, 40, 50}`

### Struktur

Jeder Datensatz (z. B. `PRGA50`) enthÃ¤lt ca. **5000 simulierte Ereignisse**.  
Jedes Ereignis ist:
- Eine Zeitreihe mit **2000 Datenpunkten**.
- Gespeichert als `.pkl` Datei mit einem einzelnen Label.
- Benannt nach dem Muster `PX_YYY.pkl`, wobei:  
  - `PX` (z. B. `P05`) das Label ist.  
  - `YYY` (z. B. `T300`) ein Identifier (nicht fÃ¼r Labels genutzt).

Die verwendeten Labels sind:
{P05, P10, P15, P20, P25, P30, P35, P40, P45, P50}

php-template
Kopieren
Bearbeiten

Diese DatensÃ¤tze werden in unterschiedlichen Kombinationen fÃ¼r **Vortraining**, **Datenaugmentation** und **Evaluation** eingesetzt.

---

## ğŸ§ª Experimentelle Setups

Um zu untersuchen, wie sich die Menge an verfÃ¼gbaren Labeldaten auf die Klassifikationsleistung auswirkt, werden die DatensÃ¤tze in acht Trainingssplits aufgeteilt:

- `train_20`, `train_50`, `train_100`, `train_200`, `train_300`,  
  `train_400`, `train_500`, `train_600`

Jeder `train_k` Split ist **kumulativ** (enthÃ¤lt also alle Samples des vorherigen Splits).  
So lÃ¤sst sich die **Skalierung der Modellleistung** bei wachsendem Datenvolumen untersuchen.

Ein spezieller Validierungssatz `val_1000` wird zur Performancebewertung verwendet.  
Dabei wird Ã¼ber mehrere Datensatz-Varianten (PRGA10â€“PRGA50) getestet, um GeneralisierungsfÃ¤higkeit unter unterschiedlichen IntensitÃ¤ten zu prÃ¼fen.

---

## ğŸ§  Klassifikator-Architektur

Das Modell in allen Experimenten ist ein **1D-CNN (Convolutional Neural Network)** mit folgender Struktur:

- **Input**: Eindimensionales Signal mit LÃ¤nge 2000.
- **Drei Convolution-BlÃ¶cke**:
  - Jeder Block: `Conv1D â†’ BatchNorm â†’ ReLU â†’ MaxPool`.
  - Kanalprogression: 1 â†’ 16 â†’ 32 â†’ 64.
- **Fully Connected Head**:
  - Flatten â†’ Dense(128) â†’ ReLU â†’ Dropout(0.5) â†’ Output Layer (10 Klassen).

Implementierung: **PyTorch**, Training mit:  
- Optimizer: Adam (`lr=1e-3`, `weight_decay=1e-5`)  
- Scheduler: StepLR (Decay alle 15 Epochen)  
- Loss: CrossEntropyLoss  
- Training: 50 Epochen (Basiswert, je nach Methode variiert)  
- Gradient Clipping: max norm = 1.0  
- Evaluation: Durchschnittliche Accuracy Ã¼ber 10 Seeds  

---

## ğŸ“Š Ergebnisse
<details>
  <summary id="baseline">Baseline</summary>
  <div align="center">
    <img src="https://i.imgur.com/gZGy95c.jpeg" alt="Baseline Ergebnis" style="max-width: 100%; height: auto;">
  </div>
</details>
<details>
  <summary id="jitter-augmentation">Jitter-Augmentation</summary>
  <div align="center">
    <img src="https://i.imgur.com/gqMoy77.jpeg" alt="Jitter Augmentation" style="max-width: 100%; height: auto;">
  </div>
</details>
<details>
  <summary id="vortraining-vergleich-methode-a-vs-methode-b">Vortraining: Vergleich Methode A vs. Methode B</summary>
  <div align="center">
    <img src="https://i.imgur.com/6oVkmdQ.jpeg" alt="Pretraining Methodenvergleich" style="max-width: 100%; height: auto;">
    <img src="https://i.imgur.com/ioQ8WmT.jpeg" alt="Diagramm 2" style="max-width: 100%; height: auto;">
  </div>
</details>
<details>
  <summary id="gan-gestÃ¼tzte-augmentation">GAN-gestÃ¼tzte Augmentation</summary>
  <div align="center">
    <img src="https://i.imgur.com/XZPKUgc.jpeg" alt="GAN Augmentation" style="max-width: 100%; height: auto;">
  </div>
</details>
<details>
  <summary id="einfaches-vortraining">Einfaches Vortraining</summary>
  <div align="center">
    <img src="https://i.imgur.com/CvEMc5p.jpeg" alt="Einfaches Vortraining" style="max-width: 100%; height: auto;">
  </div>
</details>
<details>
  <summary id="kombinierte-augmentationsmethoden">Kombinierte Augmentationsmethoden</summary>
  <div align="center">
    <img src="https://i.imgur.com/JsZxvxw.jpeg" alt="Kombinierte Methoden" style="max-width: 100%; height: auto;">
  </div>
</details>

